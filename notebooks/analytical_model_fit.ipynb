{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "sys.path.append('../src')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mvt_brr import MVTModel\n",
    "from scipy.optimize import minimize\n",
    "# from scipy.stats import pearsonr\n",
    "from world import Patch, Agent\n",
    "# from simulation import Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticChoiceModel:\n",
    "    def __init__(self, beta, intercept=0):\n",
    "        self.beta = beta\n",
    "        self.intercept = intercept\n",
    "\n",
    "    def leave_proba(self, reward):\n",
    "        \"\"\" Compute the probability of leaving given the reward. \"\"\"\n",
    "        return 1 / (1 + np.exp(self.intercept + self.beta * reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_agent_in_patch(agent, patch, max_timesteps=20):\n",
    "    patch.start_harvesting()\n",
    "    leave_probs = []\n",
    "    cumulative_prob = 1.0  # Probability of not leaving until now\n",
    "    expected_leave_time = 0.0\n",
    "    variance_leave_time = 0.0\n",
    "\n",
    "    for n in range(1, max_timesteps + 1):\n",
    "        reward = patch.get_reward()\n",
    "        prob_leave_now = agent.get_leave_probability(reward)\n",
    "        prob_leave_n = prob_leave_now * cumulative_prob\n",
    "        leave_probs.append(prob_leave_now)\n",
    "        # print(n, n * prob_leave_n)\n",
    "        expected_leave_time += n * prob_leave_n\n",
    "        cumulative_prob *= (1 - prob_leave_now)  # Update the cumulative probability\n",
    "\n",
    "    # Calculating variance\n",
    "    cumulative_prob = 1.0  # Reset for variance calculation\n",
    "    for n in range(1, max_timesteps + 1):\n",
    "        prob_leave_n = leave_probs[n-1] * cumulative_prob\n",
    "        variance_leave_time += ((n - expected_leave_time) ** 2) * prob_leave_n\n",
    "        cumulative_prob *= (1 - leave_probs[n-1])\n",
    "\n",
    "    return expected_leave_time, variance_leave_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch: low, Expected Leave Time: 11.89, Variance: 10.2753\n",
      "Patch: med, Expected Leave Time: 14.36, Variance: 9.1873\n",
      "Patch: high, Expected Leave Time: 10.55, Variance: 32.1268\n"
     ]
    }
   ],
   "source": [
    "# Example parameters\n",
    "beta, intercept = 0.3, -3\n",
    "stochastic_agent = Agent(policy_type='softmax', beta=beta, intercept=intercept)\n",
    "\n",
    "patches = {\n",
    "    'low': Patch(32.5, 0.075, 'exponential'),\n",
    "    'med': Patch(45, 0.075, 'exponential'),\n",
    "    'high': Patch(57.5, 0.075, 'exponential')\n",
    "}\n",
    "\n",
    "# Run simulations and display results\n",
    "results = {}\n",
    "for name, patch in patches.items():\n",
    "    expected_time, variance_time = simulate_agent_in_patch(stochastic_agent, patch)\n",
    "    results[name] = {'Expected Leave Time': expected_time, 'Variance': variance_time}\n",
    "\n",
    "for patch, res in results.items():\n",
    "    print(f\"Patch: {patch}, Expected Leave Time: {res['Expected Leave Time']:.2f}, Variance: {res['Variance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('../leheron_trialbytrial/leheron_blockSwitchIndex.mat')\n",
    "block_order_df = pd.read_csv('../leheron_trialbytrial/leheron_blockOrder.csv')\n",
    "df_trials = pd.read_csv(\"../leheron_trialbytrial/leheron_trialbytrial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sub  env  patch  mean_leaveT  count\n",
      "0    1    1      1    33.801510      3\n",
      "1    1    1      2    43.101277      3\n",
      "2    1    1      3    56.137283      6\n",
      "3    1    2      1    29.041616      7\n",
      "4    1    2      2    39.161016      5\n"
     ]
    }
   ],
   "source": [
    "grouped_df = df_trials.groupby(['sub', 'env', 'patch']).agg(\n",
    "    mean_leaveT=('leaveT', 'mean'),\n",
    "    count=('leaveT', 'count')\n",
    ").reset_index()\n",
    "print(grouped_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_agent_in_patch(beta, intercept, patch, max_timesteps=200):\n",
    "    agent = Agent(policy_type='softmax', beta=beta, intercept=intercept)\n",
    "    patch.start_harvesting()\n",
    "    cumulative_prob = 1.0  # Probability of not leaving until now\n",
    "    expected_leave_time = 0.0\n",
    "\n",
    "    for n in range(1, max_timesteps + 1):\n",
    "        reward = patch.get_reward()\n",
    "\n",
    "        prob_leave_now = agent.get_leave_probability(reward)\n",
    "        prob_leave_n = prob_leave_now * cumulative_prob\n",
    "        expected_leave_time += n * prob_leave_n\n",
    "        cumulative_prob *= (1 - prob_leave_now)  # Update the cumulative probability\n",
    "\n",
    "    return expected_leave_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params, df, patches, fix_intercept=None, fix_beta=None):\n",
    "    if fix_beta is not None:\n",
    "        beta = fix_beta\n",
    "        intercept = params[0]\n",
    "    elif fix_intercept is not None:\n",
    "        beta = params[0]\n",
    "        intercept = fix_intercept\n",
    "    else:\n",
    "        beta, intercept = params\n",
    "\n",
    "    total_error = 0\n",
    "    total_count = df['count'].sum()\n",
    "    patch_mapping = {1: 'low', 2: 'med', 3: 'high'}\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        patch_type, actual_mean, count = row['patch'], row['mean_leaveT'], row['count']\n",
    "        patch_name = patch_mapping[patch_type]\n",
    "        patch = patches[patch_name]\n",
    "        predicted_mean = simulate_agent_in_patch(beta, intercept, patch)\n",
    "        error = count * (predicted_mean - actual_mean) ** 2\n",
    "        total_error += error\n",
    "        \n",
    "    rmse = np.sqrt(total_error / total_count)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_parameters_for_subject(df_sub, patches):\n",
    "    initial_guess = [0.3, -3]\n",
    "    result = minimize(objective, initial_guess, args=(df_sub, patches), method='nelder-mead', options={'xatol': 1e-8, 'disp': True})\n",
    "    fitted_beta, fitted_intercept = result.x\n",
    "    return fitted_beta, fitted_intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_means(df_sub_env, fitted_beta, fitted_intercept, patches):\n",
    "    weighted_predicted_leaveT = 0\n",
    "    weighted_actual_leaveT = 0\n",
    "    total_count = df_sub_env['count'].sum()\n",
    "    patch_mapping = {1: 'low', 2: 'med', 3: 'high'}\n",
    "    \n",
    "    for _, row in df_sub_env.iterrows():\n",
    "        patch_name = patch_mapping[row['patch']]\n",
    "        patch = patches[patch_name]\n",
    "        predicted_leave_time = simulate_agent_in_patch(fitted_beta, fitted_intercept, patch)\n",
    "        weighted_predicted_leaveT += row['count'] * predicted_leave_time\n",
    "        weighted_actual_leaveT += row['count'] * row['mean_leaveT']\n",
    "\n",
    "    weighted_predicted_leaveT /= total_count\n",
    "    weighted_actual_leaveT /= total_count\n",
    "    \n",
    "    return weighted_predicted_leaveT, weighted_actual_leaveT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_case_1(grouped_df, patches):\n",
    "    results = []\n",
    "    subject_params = {}\n",
    "    \n",
    "    for sub in grouped_df['sub'].unique():\n",
    "        df_sub = grouped_df[grouped_df['sub'] == sub]\n",
    "        fitted_beta, fitted_intercept = fit_parameters_for_subject(df_sub, patches)\n",
    "        subject_params[sub] = (fitted_beta, fitted_intercept)\n",
    "        \n",
    "        for env in df_sub['env'].unique():\n",
    "            df_sub_env = df_sub[df_sub['env'] == env]\n",
    "            if not df_sub_env.empty:\n",
    "                weighted_predicted_leaveT, weighted_actual_leaveT = calculate_weighted_means(df_sub_env, fitted_beta, fitted_intercept, patches)\n",
    "                results.append({\n",
    "                    'sub': sub,\n",
    "                    'env': env,\n",
    "                    'case': 'fix_beta_fix_c',\n",
    "                    'fitted_beta': fitted_beta,\n",
    "                    'fitted_intercept': fitted_intercept,\n",
    "                    'predicted_leaveT': weighted_predicted_leaveT,\n",
    "                    'actual_mean_leaveT': weighted_actual_leaveT\n",
    "                })\n",
    "    \n",
    "    return results, subject_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fp/j9ldfbxj2_gflf_hz4bf_wyc0000gn/T/ipykernel_31139/3985341276.py:3: RuntimeWarning: Maximum number of function evaluations has been exceeded.\n",
      "  result = minimize(objective, initial_guess, args=(df_sub, patches), method='nelder-mead', options={'xatol': 1e-8, 'disp': True})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.861698\n",
      "         Iterations: 84\n",
      "         Function evaluations: 162\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.608883\n",
      "         Iterations: 101\n",
      "         Function evaluations: 195\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 4.590397\n",
      "         Iterations: 89\n",
      "         Function evaluations: 174\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.986642\n",
      "         Iterations: 86\n",
      "         Function evaluations: 166\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.361019\n",
      "         Iterations: 84\n",
      "         Function evaluations: 176\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.054548\n",
      "         Iterations: 108\n",
      "         Function evaluations: 207\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.028889\n",
      "         Iterations: 82\n",
      "         Function evaluations: 166\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.304300\n",
      "         Iterations: 96\n",
      "         Function evaluations: 195\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.582684\n",
      "         Iterations: 97\n",
      "         Function evaluations: 189\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.456464\n",
      "         Iterations: 110\n",
      "         Function evaluations: 222\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 5.051567\n",
      "         Iterations: 101\n",
      "         Function evaluations: 193\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.353222\n",
      "         Iterations: 123\n",
      "         Function evaluations: 236\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.802158\n",
      "         Iterations: 90\n",
      "         Function evaluations: 171\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.327863\n",
      "         Iterations: 93\n",
      "         Function evaluations: 177\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.720405\n",
      "         Iterations: 115\n",
      "         Function evaluations: 218\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.574142\n",
      "         Iterations: 181\n",
      "         Function evaluations: 354\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.203609\n",
      "         Iterations: 83\n",
      "         Function evaluations: 165\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.382260\n",
      "         Iterations: 123\n",
      "         Function evaluations: 241\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.652832\n",
      "         Iterations: 86\n",
      "         Function evaluations: 170\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.985306\n",
      "         Iterations: 91\n",
      "         Function evaluations: 177\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.419170\n",
      "         Iterations: 87\n",
      "         Function evaluations: 172\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.802543\n",
      "         Iterations: 154\n",
      "         Function evaluations: 286\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.228112\n",
      "         Iterations: 90\n",
      "         Function evaluations: 178\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.143052\n",
      "         Iterations: 176\n",
      "         Function evaluations: 353\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.699592\n",
      "         Iterations: 101\n",
      "         Function evaluations: 217\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.955410\n",
      "         Iterations: 83\n",
      "         Function evaluations: 161\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.210894\n",
      "         Iterations: 94\n",
      "         Function evaluations: 187\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.581530\n",
      "         Iterations: 163\n",
      "         Function evaluations: 321\n"
     ]
    }
   ],
   "source": [
    "case_1_results, subject_params = run_case_1(grouped_df, patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_case_2(grouped_df, patches, subject_params):\n",
    "    results = []\n",
    "    \n",
    "    for sub in grouped_df['sub'].unique():\n",
    "        for env in grouped_df['env'].unique():\n",
    "            df_sub_env = grouped_df[(grouped_df['sub'] == sub) & (grouped_df['env'] == env)]\n",
    "            if not df_sub_env.empty:\n",
    "                initial_guess = list(subject_params[sub])\n",
    "                result = minimize(objective, initial_guess, args=(df_sub_env, patches), method='nelder-mead', options={'xatol': 1e-8, 'disp': True})\n",
    "                fitted_beta, fitted_intercept = result.x\n",
    "                weighted_predicted_leaveT, weighted_actual_leaveT = calculate_weighted_means(df_sub_env, fitted_beta, fitted_intercept, patches)\n",
    "                results.append({\n",
    "                    'sub': sub,\n",
    "                    'env': env,\n",
    "                    'case': 'vary_beta_vary_c',\n",
    "                    'fitted_beta': fitted_beta,\n",
    "                    'fitted_intercept': fitted_intercept,\n",
    "                    'predicted_leaveT': weighted_predicted_leaveT,\n",
    "                    'actual_mean_leaveT': weighted_actual_leaveT\n",
    "                })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 6.370261\n",
      "         Iterations: 68\n",
      "         Function evaluations: 154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fp/j9ldfbxj2_gflf_hz4bf_wyc0000gn/T/ipykernel_31139/4186713115.py:9: RuntimeWarning: Maximum number of function evaluations has been exceeded.\n",
      "  result = minimize(objective, initial_guess, args=(df_sub_env, patches), method='nelder-mead', options={'xatol': 1e-8, 'disp': True})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.379589\n",
      "         Iterations: 76\n",
      "         Function evaluations: 153\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.321571\n",
      "         Iterations: 74\n",
      "         Function evaluations: 145\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.172651\n",
      "         Iterations: 99\n",
      "         Function evaluations: 211\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.629486\n",
      "         Iterations: 80\n",
      "         Function evaluations: 162\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.704506\n",
      "         Iterations: 79\n",
      "         Function evaluations: 158\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.565369\n",
      "         Iterations: 65\n",
      "         Function evaluations: 130\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.215539\n",
      "         Iterations: 70\n",
      "         Function evaluations: 137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shayan/Desktop/NOTTS/research_project/foraging/foraging_thesis/exploration_in_foraging/notebooks/../src/world.py:57: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(self.intercept + self.beta * reward))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.886516\n",
      "         Iterations: 126\n",
      "         Function evaluations: 300\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.068581\n",
      "         Iterations: 81\n",
      "         Function evaluations: 171\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.185910\n",
      "         Iterations: 93\n",
      "         Function evaluations: 181\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.007121\n",
      "         Iterations: 69\n",
      "         Function evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.154190\n",
      "         Iterations: 97\n",
      "         Function evaluations: 197\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.111397\n",
      "         Iterations: 67\n",
      "         Function evaluations: 132\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.040494\n",
      "         Iterations: 76\n",
      "         Function evaluations: 160\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.444521\n",
      "         Iterations: 102\n",
      "         Function evaluations: 268\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.319505\n",
      "         Iterations: 83\n",
      "         Function evaluations: 163\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.223620\n",
      "         Iterations: 73\n",
      "         Function evaluations: 139\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.440378\n",
      "         Iterations: 83\n",
      "         Function evaluations: 165\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.977347\n",
      "         Iterations: 88\n",
      "         Function evaluations: 172\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.833938\n",
      "         Iterations: 64\n",
      "         Function evaluations: 128\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.647671\n",
      "         Iterations: 57\n",
      "         Function evaluations: 113\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.727635\n",
      "         Iterations: 66\n",
      "         Function evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.506316\n",
      "         Iterations: 75\n",
      "         Function evaluations: 145\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.895237\n",
      "         Iterations: 119\n",
      "         Function evaluations: 290\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364268\n",
      "         Iterations: 139\n",
      "         Function evaluations: 319\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.088048\n",
      "         Iterations: 92\n",
      "         Function evaluations: 199\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.124772\n",
      "         Iterations: 71\n",
      "         Function evaluations: 149\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.102471\n",
      "         Iterations: 69\n",
      "         Function evaluations: 135\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.277310\n",
      "         Iterations: 67\n",
      "         Function evaluations: 139\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.196646\n",
      "         Iterations: 87\n",
      "         Function evaluations: 169\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.461985\n",
      "         Iterations: 168\n",
      "         Function evaluations: 334\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.826339\n",
      "         Iterations: 67\n",
      "         Function evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.499213\n",
      "         Iterations: 75\n",
      "         Function evaluations: 142\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.034049\n",
      "         Iterations: 63\n",
      "         Function evaluations: 122\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408736\n",
      "         Iterations: 77\n",
      "         Function evaluations: 156\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.117289\n",
      "         Iterations: 78\n",
      "         Function evaluations: 149\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.738404\n",
      "         Iterations: 61\n",
      "         Function evaluations: 127\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.736919\n",
      "         Iterations: 126\n",
      "         Function evaluations: 259\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.709023\n",
      "         Iterations: 120\n",
      "         Function evaluations: 303\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.601727\n",
      "         Iterations: 118\n",
      "         Function evaluations: 296\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.003852\n",
      "         Iterations: 125\n",
      "         Function evaluations: 311\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.386924\n",
      "         Iterations: 76\n",
      "         Function evaluations: 149\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.110840\n",
      "         Iterations: 75\n",
      "         Function evaluations: 149\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.764175\n",
      "         Iterations: 147\n",
      "         Function evaluations: 295\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.925897\n",
      "         Iterations: 79\n",
      "         Function evaluations: 169\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.531006\n",
      "         Iterations: 142\n",
      "         Function evaluations: 285\n"
     ]
    }
   ],
   "source": [
    "case_2_results = run_case_2(grouped_df, patches, subject_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_case_3(grouped_df, patches, subject_params):\n",
    "    results = []\n",
    "    \n",
    "    for sub in grouped_df['sub'].unique():\n",
    "        fixed_intercept = subject_params[sub][1]\n",
    "        for env in grouped_df['env'].unique():\n",
    "            df_sub_env = grouped_df[(grouped_df['sub'] == sub) & (grouped_df['env'] == env)]\n",
    "            if not df_sub_env.empty:\n",
    "                initial_guess = [subject_params[sub][0]]\n",
    "                # result = minimize(objective, initial_guess, args=(df_sub_env, patches, fixed_intercept), method='nelder-mead', options={\n",
    "                #                                                                                                                         'fatol': 1e-6,\n",
    "                #                                                                                                                         'disp': True})\n",
    "                result = minimize(objective, initial_guess, args=(df_sub_env, patches, fixed_intercept), method='nelder-mead', options={'xatol': 1e-8, 'disp': True})\n",
    "                fitted_beta = result.x[0]\n",
    "                weighted_predicted_leaveT, weighted_actual_leaveT = calculate_weighted_means(df_sub_env, fitted_beta, fixed_intercept, patches)\n",
    "                results.append({\n",
    "                    'sub': sub,\n",
    "                    'env': env,\n",
    "                    'case': 'vary_beta_fix_c',\n",
    "                    'fitted_beta': fitted_beta,\n",
    "                    'fitted_intercept': fixed_intercept,\n",
    "                    'predicted_leaveT': weighted_predicted_leaveT,\n",
    "                    'actual_mean_leaveT': weighted_actual_leaveT\n",
    "                })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 6.370261\n",
      "         Iterations: 28\n",
      "         Function evaluations: 57\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.800055\n",
      "         Iterations: 27\n",
      "         Function evaluations: 54\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.891562\n",
      "         Iterations: 21\n",
      "         Function evaluations: 42\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.534453\n",
      "         Iterations: 20\n",
      "         Function evaluations: 40\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.583654\n",
      "         Iterations: 23\n",
      "         Function evaluations: 46\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.218571\n",
      "         Iterations: 24\n",
      "         Function evaluations: 48\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.549326\n",
      "         Iterations: 23\n",
      "         Function evaluations: 46\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.024080\n",
      "         Iterations: 25\n",
      "         Function evaluations: 50\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.569225\n",
      "         Iterations: 21\n",
      "         Function evaluations: 42\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.549590\n",
      "         Iterations: 21\n",
      "         Function evaluations: 42\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.900704\n",
      "         Iterations: 29\n",
      "         Function evaluations: 60\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.069817\n",
      "         Iterations: 27\n",
      "         Function evaluations: 54\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.273093\n",
      "         Iterations: 22\n",
      "         Function evaluations: 44\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.203320\n",
      "         Iterations: 23\n",
      "         Function evaluations: 46\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.032675\n",
      "         Iterations: 21\n",
      "         Function evaluations: 42\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.640910\n",
      "         Iterations: 20\n",
      "         Function evaluations: 40\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.550357\n",
      "         Iterations: 22\n",
      "         Function evaluations: 44\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.111805\n",
      "         Iterations: 22\n",
      "         Function evaluations: 44\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.256160\n",
      "         Iterations: 25\n",
      "         Function evaluations: 50\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.413420\n",
      "         Iterations: 24\n",
      "         Function evaluations: 48\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.042140\n",
      "         Iterations: 24\n",
      "         Function evaluations: 48\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.611577\n",
      "         Iterations: 24\n",
      "         Function evaluations: 48\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.832326\n",
      "         Iterations: 23\n",
      "         Function evaluations: 46\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.782437\n",
      "         Iterations: 24\n",
      "         Function evaluations: 48\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.770163\n",
      "         Iterations: 23\n",
      "         Function evaluations: 46\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.543289\n",
      "         Iterations: 23\n",
      "         Function evaluations: 46\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.171853\n",
      "         Iterations: 24\n",
      "         Function evaluations: 48\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.247650\n",
      "         Iterations: 26\n",
      "         Function evaluations: 52\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.145997\n",
      "         Iterations: 22\n",
      "         Function evaluations: 44\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.081889\n",
      "         Iterations: 22\n",
      "         Function evaluations: 44\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.873309\n",
      "         Iterations: 20\n",
      "         Function evaluations: 40\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.651311\n",
      "         Iterations: 19\n",
      "         Function evaluations: 38\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.750650\n",
      "         Iterations: 23\n",
      "         Function evaluations: 46\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.183716\n",
      "         Iterations: 24\n",
      "         Function evaluations: 48\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.868991\n",
      "         Iterations: 21\n",
      "         Function evaluations: 42\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.442843\n",
      "         Iterations: 21\n",
      "         Function evaluations: 42\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.922940\n",
      "         Iterations: 28\n",
      "         Function evaluations: 56\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.399023\n",
      "         Iterations: 27\n",
      "         Function evaluations: 54\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.088048\n",
      "         Iterations: 27\n",
      "         Function evaluations: 54\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.465762\n",
      "         Iterations: 28\n",
      "         Function evaluations: 57\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.197652\n",
      "         Iterations: 21\n",
      "         Function evaluations: 42\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.186338\n",
      "         Iterations: 21\n",
      "         Function evaluations: 42\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.047880\n",
      "         Iterations: 22\n",
      "         Function evaluations: 44\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.436586\n",
      "         Iterations: 22\n",
      "         Function evaluations: 44\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.546620\n",
      "         Iterations: 22\n",
      "         Function evaluations: 44\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.542636\n",
      "         Iterations: 22\n",
      "         Function evaluations: 44\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.631142\n",
      "         Iterations: 23\n",
      "         Function evaluations: 47\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.512139\n",
      "         Iterations: 23\n",
      "         Function evaluations: 46\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.120616\n",
      "         Iterations: 23\n",
      "         Function evaluations: 46\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.197818\n",
      "         Iterations: 24\n",
      "         Function evaluations: 48\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.353453\n",
      "         Iterations: 25\n",
      "         Function evaluations: 50\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.255302\n",
      "         Iterations: 25\n",
      "         Function evaluations: 50\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.843621\n",
      "         Iterations: 21\n",
      "         Function evaluations: 42\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.985384\n",
      "         Iterations: 21\n",
      "         Function evaluations: 42\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.168975\n",
      "         Iterations: 20\n",
      "         Function evaluations: 40\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.732385\n",
      "         Iterations: 20\n",
      "         Function evaluations: 40\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.544714\n",
      "         Iterations: 22\n",
      "         Function evaluations: 44\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.771346\n",
      "         Iterations: 21\n",
      "         Function evaluations: 42\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.736919\n",
      "         Iterations: 24\n",
      "         Function evaluations: 48\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.891212\n",
      "         Iterations: 25\n",
      "         Function evaluations: 50\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.756899\n",
      "         Iterations: 24\n",
      "         Function evaluations: 48\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.254267\n",
      "         Iterations: 25\n",
      "         Function evaluations: 50\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.232273\n",
      "         Iterations: 26\n",
      "         Function evaluations: 52\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.478592\n",
      "         Iterations: 26\n",
      "         Function evaluations: 52\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.969439\n",
      "         Iterations: 27\n",
      "         Function evaluations: 54\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.692585\n",
      "         Iterations: 28\n",
      "         Function evaluations: 57\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.519522\n",
      "         Iterations: 21\n",
      "         Function evaluations: 42\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.321931\n",
      "         Iterations: 21\n",
      "         Function evaluations: 42\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.806190\n",
      "         Iterations: 24\n",
      "         Function evaluations: 48\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.849474\n",
      "         Iterations: 24\n",
      "         Function evaluations: 48\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.221853\n",
      "         Iterations: 23\n",
      "         Function evaluations: 46\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.321249\n",
      "         Iterations: 23\n",
      "         Function evaluations: 46\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 4.101957\n",
      "         Iterations: 24\n",
      "         Function evaluations: 48\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.150753\n",
      "         Iterations: 24\n",
      "         Function evaluations: 48\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.925897\n",
      "         Iterations: 26\n",
      "         Function evaluations: 52\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.531006\n",
      "         Iterations: 25\n",
      "         Function evaluations: 50\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.314189\n",
      "         Iterations: 25\n",
      "         Function evaluations: 50\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.276089\n",
      "         Iterations: 25\n",
      "         Function evaluations: 50\n"
     ]
    }
   ],
   "source": [
    "case_3_results = run_case_3(grouped_df, patches, subject_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_case_4(grouped_df, patches, subject_params):\n",
    "    results = []\n",
    "    \n",
    "    for sub in grouped_df['sub'].unique():\n",
    "        fixed_beta = subject_params[sub][0]\n",
    "        for env in grouped_df['env'].unique():\n",
    "            df_sub_env = grouped_df[(grouped_df['sub'] == sub) & (grouped_df['env'] == env)]\n",
    "            if not df_sub_env.empty:\n",
    "                initial_guess = [subject_params[sub][1]]\n",
    "                result = minimize(objective, initial_guess, args=(df_sub_env, patches, None, fixed_beta), method='nelder-mead', options={'xatol': 1e-8, 'disp': True})\n",
    "                fitted_intercept = result.x[0]\n",
    "                weighted_predicted_leaveT, weighted_actual_leaveT = calculate_weighted_means(df_sub_env, fixed_beta, fitted_intercept, patches)\n",
    "                results.append({\n",
    "                    'sub': sub,\n",
    "                    'env': env,\n",
    "                    'case': 'fix_beta_vary_c',\n",
    "                    'fitted_beta': fixed_beta,\n",
    "                    'fitted_intercept': fitted_intercept,\n",
    "                    'predicted_leaveT': weighted_predicted_leaveT,\n",
    "                    'actual_mean_leaveT': weighted_actual_leaveT\n",
    "                })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 6.370261\n",
      "         Iterations: 31\n",
      "         Function evaluations: 65\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.800054\n",
      "         Iterations: 31\n",
      "         Function evaluations: 63\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.851042\n",
      "         Iterations: 26\n",
      "         Function evaluations: 52\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.489891\n",
      "         Iterations: 26\n",
      "         Function evaluations: 52\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.415566\n",
      "         Iterations: 27\n",
      "         Function evaluations: 54\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.368950\n",
      "         Iterations: 27\n",
      "         Function evaluations: 54\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.041004\n",
      "         Iterations: 27\n",
      "         Function evaluations: 54\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.683839\n",
      "         Iterations: 27\n",
      "         Function evaluations: 54\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.565855\n",
      "         Iterations: 27\n",
      "         Function evaluations: 55\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.669596\n",
      "         Iterations: 26\n",
      "         Function evaluations: 52\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.897297\n",
      "         Iterations: 33\n",
      "         Function evaluations: 69\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.069223\n",
      "         Iterations: 32\n",
      "         Function evaluations: 66\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.273112\n",
      "         Iterations: 28\n",
      "         Function evaluations: 57\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.203567\n",
      "         Iterations: 26\n",
      "         Function evaluations: 53\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.040757\n",
      "         Iterations: 25\n",
      "         Function evaluations: 50\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.669293\n",
      "         Iterations: 24\n",
      "         Function evaluations: 49\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.460039\n",
      "         Iterations: 28\n",
      "         Function evaluations: 57\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.117834\n",
      "         Iterations: 29\n",
      "         Function evaluations: 58\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.256160\n",
      "         Iterations: 29\n",
      "         Function evaluations: 59\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.413420\n",
      "         Iterations: 28\n",
      "         Function evaluations: 57\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.040712\n",
      "         Iterations: 29\n",
      "         Function evaluations: 59\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.614520\n",
      "         Iterations: 30\n",
      "         Function evaluations: 63\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.599292\n",
      "         Iterations: 28\n",
      "         Function evaluations: 56\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.984418\n",
      "         Iterations: 28\n",
      "         Function evaluations: 57\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.727565\n",
      "         Iterations: 29\n",
      "         Function evaluations: 58\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.556713\n",
      "         Iterations: 29\n",
      "         Function evaluations: 58\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.526070\n",
      "         Iterations: 27\n",
      "         Function evaluations: 55\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.474677\n",
      "         Iterations: 26\n",
      "         Function evaluations: 52\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.952765\n",
      "         Iterations: 27\n",
      "         Function evaluations: 54\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.205802\n",
      "         Iterations: 26\n",
      "         Function evaluations: 52\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.864994\n",
      "         Iterations: 25\n",
      "         Function evaluations: 50\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.648257\n",
      "         Iterations: 25\n",
      "         Function evaluations: 50\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.767692\n",
      "         Iterations: 26\n",
      "         Function evaluations: 52\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.759767\n",
      "         Iterations: 25\n",
      "         Function evaluations: 50\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.862875\n",
      "         Iterations: 23\n",
      "         Function evaluations: 46\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.435175\n",
      "         Iterations: 24\n",
      "         Function evaluations: 48\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.914976\n",
      "         Iterations: 33\n",
      "         Function evaluations: 70\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.407314\n",
      "         Iterations: 33\n",
      "         Function evaluations: 69\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.088048\n",
      "         Iterations: 30\n",
      "         Function evaluations: 62\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.465762\n",
      "         Iterations: 30\n",
      "         Function evaluations: 63\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.200029\n",
      "         Iterations: 23\n",
      "         Function evaluations: 46\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.189246\n",
      "         Iterations: 22\n",
      "         Function evaluations: 44\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.838834\n",
      "         Iterations: 26\n",
      "         Function evaluations: 52\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.588161\n",
      "         Iterations: 25\n",
      "         Function evaluations: 50\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.450765\n",
      "         Iterations: 29\n",
      "         Function evaluations: 58\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.639010\n",
      "         Iterations: 29\n",
      "         Function evaluations: 58\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.631142\n",
      "         Iterations: 28\n",
      "         Function evaluations: 57\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.512139\n",
      "         Iterations: 27\n",
      "         Function evaluations: 54\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.726880\n",
      "         Iterations: 27\n",
      "         Function evaluations: 54\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.701748\n",
      "         Iterations: 27\n",
      "         Function evaluations: 54\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.353453\n",
      "         Iterations: 28\n",
      "         Function evaluations: 57\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.255302\n",
      "         Iterations: 28\n",
      "         Function evaluations: 57\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.889648\n",
      "         Iterations: 26\n",
      "         Function evaluations: 52\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.188429\n",
      "         Iterations: 25\n",
      "         Function evaluations: 50\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.240625\n",
      "         Iterations: 25\n",
      "         Function evaluations: 50\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.799725\n",
      "         Iterations: 25\n",
      "         Function evaluations: 50\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.466425\n",
      "         Iterations: 26\n",
      "         Function evaluations: 52\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.805106\n",
      "         Iterations: 25\n",
      "         Function evaluations: 50\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.736919\n",
      "         Iterations: 29\n",
      "         Function evaluations: 61\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.891212\n",
      "         Iterations: 27\n",
      "         Function evaluations: 55\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.756899\n",
      "         Iterations: 30\n",
      "         Function evaluations: 64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.254267\n",
      "         Iterations: 28\n",
      "         Function evaluations: 59\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.232272\n",
      "         Iterations: 30\n",
      "         Function evaluations: 61\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.478592\n",
      "         Iterations: 31\n",
      "         Function evaluations: 63\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.969423\n",
      "         Iterations: 31\n",
      "         Function evaluations: 63\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 3.692585\n",
      "         Iterations: 31\n",
      "         Function evaluations: 63\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.478351\n",
      "         Iterations: 27\n",
      "         Function evaluations: 54\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.395383\n",
      "         Iterations: 27\n",
      "         Function evaluations: 54\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.806190\n",
      "         Iterations: 27\n",
      "         Function evaluations: 56\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.849474\n",
      "         Iterations: 27\n",
      "         Function evaluations: 55\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.079735\n",
      "         Iterations: 28\n",
      "         Function evaluations: 56\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.408869\n",
      "         Iterations: 27\n",
      "         Function evaluations: 54\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 4.101957\n",
      "         Iterations: 28\n",
      "         Function evaluations: 60\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.150753\n",
      "         Iterations: 27\n",
      "         Function evaluations: 55\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.925897\n",
      "         Iterations: 28\n",
      "         Function evaluations: 57\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.531006\n",
      "         Iterations: 29\n",
      "         Function evaluations: 60\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.314189\n",
      "         Iterations: 30\n",
      "         Function evaluations: 61\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.276089\n",
      "         Iterations: 31\n",
      "         Function evaluations: 65\n"
     ]
    }
   ],
   "source": [
    "case_4_results = run_case_4(grouped_df, patches, subject_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = case_1_results + case_2_results + case_3_results + case_4_results\n",
    "results_df = pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub</th>\n",
       "      <th>env</th>\n",
       "      <th>case</th>\n",
       "      <th>fitted_beta</th>\n",
       "      <th>fitted_intercept</th>\n",
       "      <th>predicted_leaveT</th>\n",
       "      <th>actual_mean_leaveT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>fix_beta_fix_c</td>\n",
       "      <td>0.073163</td>\n",
       "      <td>1.474161</td>\n",
       "      <td>19.548446</td>\n",
       "      <td>16.733743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>fix_beta_fix_c</td>\n",
       "      <td>0.073163</td>\n",
       "      <td>1.474161</td>\n",
       "      <td>17.257057</td>\n",
       "      <td>20.564042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>vary_beta_vary_c</td>\n",
       "      <td>0.364397</td>\n",
       "      <td>-4.343233</td>\n",
       "      <td>16.733739</td>\n",
       "      <td>16.733743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>vary_beta_vary_c</td>\n",
       "      <td>0.801783</td>\n",
       "      <td>-6.513515</td>\n",
       "      <td>20.564046</td>\n",
       "      <td>20.564042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>vary_beta_fix_c</td>\n",
       "      <td>0.057667</td>\n",
       "      <td>1.474161</td>\n",
       "      <td>16.892092</td>\n",
       "      <td>16.733743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>vary_beta_fix_c</td>\n",
       "      <td>0.098474</td>\n",
       "      <td>1.474161</td>\n",
       "      <td>20.654309</td>\n",
       "      <td>20.564042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>fix_beta_vary_c</td>\n",
       "      <td>0.073163</td>\n",
       "      <td>1.126248</td>\n",
       "      <td>16.765131</td>\n",
       "      <td>16.733743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>fix_beta_vary_c</td>\n",
       "      <td>0.073163</td>\n",
       "      <td>1.829577</td>\n",
       "      <td>20.597678</td>\n",
       "      <td>20.564042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sub  env              case  fitted_beta  fitted_intercept  \\\n",
       "4      3    1    fix_beta_fix_c     0.073163          1.474161   \n",
       "5      3    2    fix_beta_fix_c     0.073163          1.474161   \n",
       "82     3    1  vary_beta_vary_c     0.364397         -4.343233   \n",
       "83     3    2  vary_beta_vary_c     0.801783         -6.513515   \n",
       "160    3    1   vary_beta_fix_c     0.057667          1.474161   \n",
       "161    3    2   vary_beta_fix_c     0.098474          1.474161   \n",
       "238    3    1   fix_beta_vary_c     0.073163          1.126248   \n",
       "239    3    2   fix_beta_vary_c     0.073163          1.829577   \n",
       "\n",
       "     predicted_leaveT  actual_mean_leaveT  \n",
       "4           19.548446           16.733743  \n",
       "5           17.257057           20.564042  \n",
       "82          16.733739           16.733743  \n",
       "83          20.564046           20.564042  \n",
       "160         16.892092           16.733743  \n",
       "161         20.654309           20.564042  \n",
       "238         16.765131           16.733743  \n",
       "239         20.597678           20.564042  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df[\"sub\"]==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse_for_cases(results_df):\n",
    "    results = []\n",
    "    \n",
    "    for sub in results_df['sub'].unique():\n",
    "        sub_data = results_df[results_df['sub'] == sub]\n",
    "        \n",
    "        for case in sub_data['case'].unique():\n",
    "            case_data = sub_data[sub_data['case'] == case]\n",
    "            n = len(case_data)\n",
    "            rss = np.sum((case_data['actual_mean_leaveT'] - case_data['predicted_leaveT']) ** 2)\n",
    "            rmse = np.sqrt(rss / n)\n",
    "            results.append({\n",
    "                'sub': sub,\n",
    "                'case': case,\n",
    "                'rmse': rmse\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "rmse_df = calculate_rmse_for_cases(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_winning_cases(rmse_df):\n",
    "    # Find the minimum RMSE for each subject\n",
    "    winning_cases = rmse_df.loc[rmse_df.groupby('sub')['rmse'].idxmin()]\n",
    "    \n",
    "    # Count the number of subjects for each case\n",
    "    case_counts = winning_cases['case'].value_counts().reindex([\n",
    "        'vary_beta_vary_c', 'vary_beta_fix_c', 'fix_beta_vary_c', 'fix_beta_fix_c'\n",
    "    ], fill_value=0)\n",
    "    \n",
    "    return case_counts, winning_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_winning_cases_histogram(case_counts):\n",
    "    cases = ['vary $\\\\beta$, vary c', 'vary $\\\\beta$, fix c', 'fix $\\\\beta$, vary c', 'fix $\\\\beta$, fix c']\n",
    "    case_counts_sorted = [\n",
    "        case_counts['vary_beta_vary_c'], \n",
    "        case_counts['vary_beta_fix_c'], \n",
    "        case_counts['fix_beta_vary_c'], \n",
    "        case_counts['fix_beta_fix_c']\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.bar(cases, case_counts_sorted, color='pink')\n",
    "    plt.ylabel('Number of subjects')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_counts, winning_cases = find_winning_cases(rmse_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case\n",
       "vary_beta_vary_c    23\n",
       "vary_beta_fix_c      6\n",
       "fix_beta_vary_c     10\n",
       "fix_beta_fix_c       0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_winning_cases_histogram(case_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub</th>\n",
       "      <th>patch</th>\n",
       "      <th>env</th>\n",
       "      <th>leaveT</th>\n",
       "      <th>meanLT</th>\n",
       "      <th>dmLeave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>45.034784</td>\n",
       "      <td>40.532927</td>\n",
       "      <td>4.501856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>44.403900</td>\n",
       "      <td>40.532927</td>\n",
       "      <td>3.870973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>61.168672</td>\n",
       "      <td>40.532927</td>\n",
       "      <td>20.635745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.803514</td>\n",
       "      <td>40.532927</td>\n",
       "      <td>-13.729413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>56.992002</td>\n",
       "      <td>40.532927</td>\n",
       "      <td>16.459075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sub  patch  env     leaveT     meanLT    dmLeave\n",
       "0    1      3    1  45.034784  40.532927   4.501856\n",
       "1    1      2    1  44.403900  40.532927   3.870973\n",
       "2    1      3    1  61.168672  40.532927  20.635745\n",
       "3    1      1    1  26.803514  40.532927 -13.729413\n",
       "4    1      3    1  56.992002  40.532927  16.459075"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trials.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_types = [\n",
    "    {'type': 'Low', 'initial_yield': 32.5, 'decay_rate': 0.075},\n",
    "    {'type': 'Mid', 'initial_yield': 45, 'decay_rate': 0.075},\n",
    "    {'type': 'High', 'initial_yield': 57.5, 'decay_rate': 0.075}\n",
    "]\n",
    "patch_type = patch_types[1]\n",
    "patch_type['initial_yield']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_leave_time(row, parameters, case):\n",
    "    beta = parameters.loc[(parameters['sub'] == row['sub']) & (parameters['env'] == row['env']) & (parameters['case'] == case), 'fitted_beta'].values[0]\n",
    "    intercept = parameters.loc[(parameters['sub'] == row['sub']) & (parameters['env'] == row['env']) & (parameters['case'] == case), 'fitted_intercept'].values[0]\n",
    "    patch_type = patch_types[int(row['patch']-1)]\n",
    "    patch = Patch(patch_type['initial_yield'], patch_type['decay_rate'])\n",
    "    predicted_leave_time = simulate_agent_in_patch(beta, intercept, patch, max_timesteps=200)\n",
    "    \n",
    "    return predicted_leave_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse_for_subjects(df_trials, results_df, case):\n",
    "    df_trials[f'predicted_leaveT_{case}'] = df_trials.apply(predict_leave_time, axis=1, parameters=results_df, case=case)\n",
    "    \n",
    "    rmse_results = []\n",
    "    for sub in df_trials['sub'].unique():\n",
    "        sub_data = df_trials[df_trials['sub'] == sub]\n",
    "        rss = np.sum((sub_data['leaveT'] - sub_data[f'predicted_leaveT_{case}']) ** 2)\n",
    "        rmse = np.sqrt(rss / len(sub_data))\n",
    "        rmse_results.append({'sub': sub, 'rmse': rmse, 'case': case})\n",
    "    \n",
    "    return pd.DataFrame(rmse_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all_rmse(df_trials, results_df):\n",
    "    cases = ['vary_beta_vary_c', 'vary_beta_fix_c', 'fix_beta_vary_c', 'fix_beta_fix_c']\n",
    "    all_rmse = []\n",
    "\n",
    "    for case in cases:\n",
    "        rmse_df = calculate_rmse_for_subjects(df_trials, results_df, case)\n",
    "        all_rmse.append(rmse_df)\n",
    "    \n",
    "    all_rmse_df = pd.concat(all_rmse, ignore_index=True)\n",
    "    \n",
    "    # Find the winning case with minimum RMSE for each subject\n",
    "    # winning_cases = all_rmse_df.loc[all_rmse_df.groupby('sub')['rmse'].idxmin()]\n",
    "\n",
    "    # Sum RMSE for each case\n",
    "    rmse_sums = all_rmse_df.groupby('case')['rmse'].sum()\n",
    "\n",
    "    # return all_rmse_df, winning_cases\n",
    "    return all_rmse_df, rmse_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_winning_cases_histogram(case_counts):\n",
    "    cases = ['vary $\\\\beta$, vary c', 'vary $\\\\beta$, fix c', 'fix $\\\\beta$, vary c', 'fix $\\\\beta$, fix c']\n",
    "    case_counts_sorted = [\n",
    "        case_counts['vary_beta_vary_c'], \n",
    "        case_counts['vary_beta_fix_c'], \n",
    "        case_counts['fix_beta_vary_c'], \n",
    "        case_counts['fix_beta_fix_c']\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.bar(cases, case_counts_sorted, color='pink')\n",
    "    plt.ylabel('Number of subjects')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rmse_sums(rmse_sums):\n",
    "    cases = ['vary_beta_vary_c', 'vary_beta_fix_c', 'fix_beta_vary_c', 'fix_beta_fix_c']\n",
    "    rmse_values_sorted = [rmse_sums[case] for case in cases]\n",
    "\n",
    "    plt.figure(figsize=(4, 5))\n",
    "    plt.bar(cases, rmse_values_sorted, color='pink')\n",
    "    plt.ylabel('Sum of RMSE')\n",
    "    plt.ylim(150, 180)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shayan/Desktop/NOTTS/research_project/foraging/foraging_thesis/exploration_in_foraging/notebooks/../src/world.py:57: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(self.intercept + self.beta * reward))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate RMSE for all cases and find the winning case for each subject\n",
    "# all_rmse_df, winning_cases = calculate_all_rmse(df_trials, results_df)\n",
    "# case_counts = winning_cases['case'].value_counts()\n",
    "# plot_winning_cases_histogram(case_counts)\n",
    "\n",
    "all_rmse_df, rmse_sums = calculate_all_rmse(df_trials, results_df)\n",
    "plot_rmse_sums(rmse_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub</th>\n",
       "      <th>env</th>\n",
       "      <th>case</th>\n",
       "      <th>policy_type</th>\n",
       "      <th>fitted_parameter</th>\n",
       "      <th>fitted_intercept</th>\n",
       "      <th>predicted_leaveT</th>\n",
       "      <th>actual_mean_leaveT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>fix_parameter_fix_c</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.073163</td>\n",
       "      <td>1.474161</td>\n",
       "      <td>19.548446</td>\n",
       "      <td>16.733743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>fix_parameter_fix_c</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.073163</td>\n",
       "      <td>1.474161</td>\n",
       "      <td>17.257057</td>\n",
       "      <td>20.564042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>vary_parameter_vary_c</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.364397</td>\n",
       "      <td>-4.343233</td>\n",
       "      <td>16.733739</td>\n",
       "      <td>16.733743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>vary_parameter_vary_c</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.801783</td>\n",
       "      <td>-6.513515</td>\n",
       "      <td>20.564046</td>\n",
       "      <td>20.564042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>vary_parameter_fix_c</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.057667</td>\n",
       "      <td>1.474161</td>\n",
       "      <td>16.892092</td>\n",
       "      <td>16.733743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>vary_parameter_fix_c</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.098474</td>\n",
       "      <td>1.474161</td>\n",
       "      <td>20.654309</td>\n",
       "      <td>20.564042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>fix_parameter_vary_c</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.073163</td>\n",
       "      <td>1.126248</td>\n",
       "      <td>16.765131</td>\n",
       "      <td>16.733743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>fix_parameter_vary_c</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.073163</td>\n",
       "      <td>1.829577</td>\n",
       "      <td>20.597678</td>\n",
       "      <td>20.564042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sub  env                   case policy_type  fitted_parameter  \\\n",
       "4      3    1    fix_parameter_fix_c     softmax          0.073163   \n",
       "5      3    2    fix_parameter_fix_c     softmax          0.073163   \n",
       "82     3    1  vary_parameter_vary_c     softmax          0.364397   \n",
       "83     3    2  vary_parameter_vary_c     softmax          0.801783   \n",
       "160    3    1   vary_parameter_fix_c     softmax          0.057667   \n",
       "161    3    2   vary_parameter_fix_c     softmax          0.098474   \n",
       "238    3    1   fix_parameter_vary_c     softmax          0.073163   \n",
       "239    3    2   fix_parameter_vary_c     softmax          0.073163   \n",
       "\n",
       "     fitted_intercept  predicted_leaveT  actual_mean_leaveT  \n",
       "4            1.474161         19.548446           16.733743  \n",
       "5            1.474161         17.257057           20.564042  \n",
       "82          -4.343233         16.733739           16.733743  \n",
       "83          -6.513515         20.564046           20.564042  \n",
       "160          1.474161         16.892092           16.733743  \n",
       "161          1.474161         20.654309           20.564042  \n",
       "238          1.126248         16.765131           16.733743  \n",
       "239          1.829577         20.597678           20.564042  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_res_df = pd.read_csv(\"../src/optimization_results_softmax.csv\")\n",
    "new_res_df[new_res_df[\"sub\"]==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rmse_df = calculate_rmse_for_cases(new_res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_counts, winning_cases = find_winning_cases(new_rmse_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case\n",
       "vary_beta_vary_c    0\n",
       "vary_beta_fix_c     0\n",
       "fix_beta_vary_c     0\n",
       "fix_beta_fix_c      0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub</th>\n",
       "      <th>case</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>fix_parameter_fix_c</td>\n",
       "      <td>5.220099e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>vary_parameter_vary_c</td>\n",
       "      <td>1.758770e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>vary_parameter_fix_c</td>\n",
       "      <td>8.595456e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>fix_parameter_vary_c</td>\n",
       "      <td>1.861098e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>fix_parameter_fix_c</td>\n",
       "      <td>5.502129e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>38</td>\n",
       "      <td>fix_parameter_vary_c</td>\n",
       "      <td>1.447092e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>39</td>\n",
       "      <td>fix_parameter_fix_c</td>\n",
       "      <td>1.571767e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>39</td>\n",
       "      <td>vary_parameter_vary_c</td>\n",
       "      <td>6.215521e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>39</td>\n",
       "      <td>vary_parameter_fix_c</td>\n",
       "      <td>3.387905e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>39</td>\n",
       "      <td>fix_parameter_vary_c</td>\n",
       "      <td>4.506309e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sub                   case          rmse\n",
       "0      1    fix_parameter_fix_c  5.220099e+00\n",
       "1      1  vary_parameter_vary_c  1.758770e-06\n",
       "2      1   vary_parameter_fix_c  8.595456e-07\n",
       "3      1   fix_parameter_vary_c  1.861098e-07\n",
       "4      2    fix_parameter_fix_c  5.502129e-01\n",
       "..   ...                    ...           ...\n",
       "151   38   fix_parameter_vary_c  1.447092e-07\n",
       "152   39    fix_parameter_fix_c  1.571767e+00\n",
       "153   39  vary_parameter_vary_c  6.215521e-06\n",
       "154   39   vary_parameter_fix_c  3.387905e-07\n",
       "155   39   fix_parameter_vary_c  4.506309e-08\n",
       "\n",
       "[156 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rmse_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_foraging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
